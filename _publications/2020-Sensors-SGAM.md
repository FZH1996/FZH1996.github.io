---
title: "Focus on the visible regions: semantic-guided alignment model for occluded person re-identification"
collection: publications
permalink: /publication/2020-Sensors-SGAM
excerpt: 'topic: Semantic-guided Alignment in Person Re-identification.'
date: 2020-07-01
venue: 'Sensors'
paperurl: '(https://www.mdpi.com/1424-8220/20/16/4431/htm)'
citation: 'Q. Yang, P. Wang, Z. Fang and Q. Lu. &quot;Focus on the visible regions: semantic-guided alignment model for occluded person re-identification.&quot; <i>Sensors</i>, 2020, 20(16): 4431.'
---

- When persons are occluded by various obstacles, the noise caused by the occluded area greatly affects the pedestrian retrieval results.
- We propose a semantic-guided alignment model that uses image semantic information to separate useful information from occlusion noise.
- We fuse the probability maps with the global features of the image, and derive an automatic cropping method to guide the model to focus on public visible human regions and local features.
- We propose a measurement strategy that only calculates the distance of public areas between images, thereby suppressing the spatial misalignment.
- Experimental results confirm that our method achieves top performance in the holistic pedestrian re-identification problem.

[Download paper here](https://fzh1996.github.io/files/ZihanFang_Sensors2020.pdf)

Recommended citation: Q. Yang, P. Wang, Z. Fang and Q. Lu, Focus on the visible regions: semantic-guided alignment model for occluded person re-identification. <i>Sensors</i>, 2020, 20(16): 4431.
